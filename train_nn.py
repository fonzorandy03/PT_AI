"""
PT AI Model Training - VERSIONE AVANZATA PER TESI
=================================================
Feature Engineering Avanzato + Bilanciamento Dataset + Data Augmentation
Training professionale con metriche complete per tesi di laurea

Autore: Alfonso (Tesi di Laurea)
Data: 2025
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.utils import resample
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.regularizers import l2
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import json
import os
from datetime import datetime
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import precision_recall_fscore_support
import warnings
warnings.filterwarnings('ignore')

# ============================================
# CONFIGURAZIONE
# ============================================

DATASET_PATH = "exercise_angles.csv"
OUTPUT_DIR = "pt_ai_model_advanced"
MODEL_NAME = "pt_ai_nn_model"
EPOCHS = 150
BATCH_SIZE = 32
VALIDATION_SPLIT = 0.15
TEST_SPLIT = 0.15
RANDOM_STATE = 42

# Feature engineering settings
ENABLE_ADVANCED_FEATURES = True
ENABLE_DATA_AUGMENTATION = True
AUGMENTATION_FACTOR = 2  # Moltiplica dataset per 2x

# Crea directory output
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("="*80)
print("üéì PT AI MODEL TRAINING - VERSIONE AVANZATA PER TESI")
print("="*80)
print(f"üìÖ Data: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"üìÇ Dataset: {DATASET_PATH}")
print(f"üíæ Output: {OUTPUT_DIR}/")
print(f"üî¨ Feature Engineering Avanzato: {'ATTIVO' if ENABLE_ADVANCED_FEATURES else 'DISATTIVO'}")
print(f"üìà Data Augmentation: {'ATTIVO' if ENABLE_DATA_AUGMENTATION else 'DISATTIVO'}")
print("="*80)

# ============================================
# FUNZIONI DI FEATURE ENGINEERING
# ============================================

def calculate_distances(row):
    """
    Calcola distanze euclidee tra landmark chiave
    CRITICO per distinguere esercizi dinamici
    """
    features = {}
    
    # Simulazione posizioni landmark (assumo siano nel dataset)
    # In un dataset reale, queste coordinate dovrebbero essere presenti
    # Per ora lavoriamo con gli angoli e creiamo features derivate
    
    # 1. Simmetria corporea (differenze lato sinistro/destro)
    features['elbow_symmetry'] = abs(row.get('Left Elbow Angle', 0) - row.get('Right Elbow Angle', 0))
    features['knee_symmetry'] = abs(row.get('Left Knee Angle', 0) - row.get('Right Knee Angle', 0))
    features['shoulder_symmetry'] = abs(row.get('Left Shoulder Angle', 0) - row.get('Right Shoulder Angle', 0))
    features['hip_symmetry'] = abs(row.get('Left Hip Angle', 0) - row.get('Right Hip Angle', 0))
    
    # 2. Medie angoli per ridurre rumore
    features['avg_elbow'] = (row.get('Left Elbow Angle', 0) + row.get('Right Elbow Angle', 0)) / 2
    features['avg_knee'] = (row.get('Left Knee Angle', 0) + row.get('Right Knee Angle', 0)) / 2
    features['avg_shoulder'] = (row.get('Left Shoulder Angle', 0) + row.get('Right Shoulder Angle', 0)) / 2
    features['avg_hip'] = (row.get('Left Hip Angle', 0) + row.get('Right Hip Angle', 0)) / 2
    
    # 3. Range of Motion (ROM) indicators
    features['upper_body_flexion'] = features['avg_elbow'] + features['avg_shoulder']
    features['lower_body_flexion'] = features['avg_knee'] + features['avg_hip']
    
    # 4. Indicatori postura
    features['body_extension'] = (features['avg_hip'] + features['avg_knee']) / 2
    features['arms_position'] = (features['avg_shoulder'] + features['avg_elbow']) / 2
    
    # 5. Ratios (rapporti) tra angoli - utili per pattern recognition
    features['shoulder_knee_ratio'] = features['avg_shoulder'] / (features['avg_knee'] + 1e-5)
    features['elbow_hip_ratio'] = features['avg_elbow'] / (features['avg_hip'] + 1e-5)
    
    return features


def add_temporal_features(df, window_size=3):
    """
    Aggiunge features temporali (velocit√† di movimento, accelerazione)
    IMPORTANTE: Simula sequenze temporali per esercizi dinamici
    """
    temporal_features = {}
    
    angle_columns = ['Left Elbow Angle', 'Right Elbow Angle', 
                     'Left Knee Angle', 'Right Knee Angle',
                     'Left Shoulder Angle', 'Right Shoulder Angle',
                     'Left Hip Angle', 'Right Hip Angle']
    
    for col in angle_columns:
        if col in df.columns:
            # Velocit√† (differenza tra frame consecutivi)
            df[f'{col}_velocity'] = df[col].diff().fillna(0)
            
            # Accelerazione (variazione della velocit√†)
            df[f'{col}_acceleration'] = df[f'{col}_velocity'].diff().fillna(0)
            
            # Moving average per smoothing
            df[f'{col}_smooth'] = df[col].rolling(window=window_size, min_periods=1).mean()
    
    return df


def augment_data(X, y, label_encoder, augmentation_factor=2):
    """
    Data Augmentation: Crea variazioni dei dati per aumentare robustezza
    - Aggiunge rumore gaussiano
    - Scala angoli leggermente
    - Perturba simmetria
    """
    print(f"\nüîÑ Data Augmentation (factor: {augmentation_factor}x)...")
    
    augmented_X = [X]
    augmented_y = [y]
    
    for i in range(augmentation_factor - 1):
        # Copia dei dati
        X_aug = X.copy()
        
        # 1. Aggiungi rumore gaussiano (simula variazioni naturali)
        noise = np.random.normal(0, 0.02, X_aug.shape)
        X_aug += noise
        
        # 2. Scala casuale (simula diverse persone/proporzioni)
        scale = np.random.uniform(0.95, 1.05, (X_aug.shape[0], 1))
        X_aug *= scale
        
        augmented_X.append(X_aug)
        augmented_y.append(y)
    
    # Combina tutti i dati
    X_augmented = np.vstack(augmented_X)
    y_augmented = np.vstack(augmented_y)
    
    print(f"   Dataset originale: {X.shape[0]} samples")
    print(f"   Dataset augmented: {X_augmented.shape[0]} samples")
    print(f"   ‚úÖ Aumento: {X_augmented.shape[0] / X.shape[0]:.1f}x")
    
    return X_augmented, y_augmented


def balance_dataset(X, y, label_encoder):
    """
    Bilancia il dataset usando SMOTE-like oversampling
    CRITICO: Evita bias verso classi maggioritarie (es. Squats)
    """
    print(f"\n‚öñÔ∏è  Bilanciamento dataset...")
    
    # Converti one-hot encoding a labels
    y_labels = np.argmax(y, axis=1)
    
    # Conta campioni per classe
    unique, counts = np.unique(y_labels, return_counts=True)
    class_distribution = dict(zip(unique, counts))
    
    print(f"   Distribuzione originale:")
    for class_idx, count in class_distribution.items():
        class_name = label_encoder.inverse_transform([class_idx])[0]
        print(f"      {class_name}: {count} samples ({count/len(y_labels)*100:.1f}%)")
    
    # Trova classe maggioritaria
    max_samples = max(counts)
    
    # Oversample classi minoritarie
    X_balanced = []
    y_balanced = []
    
    for class_idx in unique:
        # Estrai samples di questa classe
        mask = y_labels == class_idx
        X_class = X[mask]
        y_class = y[mask]
        
        # Quanti samples servono?
        n_samples = len(X_class)
        n_needed = max_samples - n_samples
        
        if n_needed > 0:
            # Oversample con rumore
            indices = np.random.choice(n_samples, n_needed, replace=True)
            X_oversampled = X_class[indices]
            y_oversampled = y_class[indices]
            
            # Aggiungi rumore per variabilit√†
            noise = np.random.normal(0, 0.01, X_oversampled.shape)
            X_oversampled += noise
            
            # Combina originali + oversampled
            X_balanced.append(X_class)
            X_balanced.append(X_oversampled)
            y_balanced.append(y_class)
            y_balanced.append(y_oversampled)
        else:
            X_balanced.append(X_class)
            y_balanced.append(y_class)
    
    X_balanced = np.vstack(X_balanced)
    y_balanced = np.vstack(y_balanced)
    
    # Shuffle
    indices = np.random.permutation(len(X_balanced))
    X_balanced = X_balanced[indices]
    y_balanced = y_balanced[indices]
    
    print(f"\n   Distribuzione bilanciata:")
    y_labels_balanced = np.argmax(y_balanced, axis=1)
    unique, counts = np.unique(y_labels_balanced, return_counts=True)
    for class_idx, count in zip(unique, counts):
        class_name = label_encoder.inverse_transform([class_idx])[0]
        print(f"      {class_name}: {count} samples ({count/len(y_labels_balanced)*100:.1f}%)")
    
    return X_balanced, y_balanced


# ============================================
# CARICAMENTO E PREPROCESSING DATASET
# ============================================

print("\nüìä Caricamento dataset...")
try:
    df = pd.read_csv(DATASET_PATH)
    print(f"‚úÖ Dataset caricato: {df.shape[0]} righe, {df.shape[1]} colonne")
    print(f"\nüìã Colonne presenti:")
    for col in df.columns:
        print(f"   - {col}")
    
    print(f"\nüìä Esercizi nel dataset:")
    exercise_counts = df['Label'].value_counts()
    for exercise, count in exercise_counts.items():
        print(f"   - {exercise}: {count} samples ({count/len(df)*100:.1f}%)")
    
except FileNotFoundError:
    print(f"‚ùå ERRORE: File '{DATASET_PATH}' non trovato!")
    print("   Scarica il dataset da:")
    print("   https://www.kaggle.com/datasets/mrigaankjaswal/exercise-detection-dataset")
    exit(1)

# ============================================
# FEATURE ENGINEERING AVANZATO
# ============================================

print(f"\nüî¨ Feature Engineering Avanzato...")

if ENABLE_ADVANCED_FEATURES:
    print("   ‚úÖ Calcolo features geometriche...")
    
    # 1. Aggiungi features geometriche derivate
    advanced_features = df.apply(calculate_distances, axis=1, result_type='expand')
    df = pd.concat([df, advanced_features], axis=1)
    print(f"      Features geometriche aggiunte: {len(advanced_features.columns)}")
    
    # 2. Aggiungi features temporali (simula velocit√†)
    print("   ‚úÖ Calcolo features temporali...")
    df = add_temporal_features(df, window_size=3)
    velocity_cols = [col for col in df.columns if 'velocity' in col]
    acceleration_cols = [col for col in df.columns if 'acceleration' in col]
    print(f"      Features velocit√†: {len(velocity_cols)}")
    print(f"      Features accelerazione: {len(acceleration_cols)}")
    
    print(f"\n   üìä Totale features: {df.shape[1]}")

# ============================================
# PREPROCESSING
# ============================================

print(f"\nüîß Preprocessing...")

# Separa labels
labels = df['Label']

# Rimuovi colonne non necessarie
columns_to_drop = ['Label']
if 'Side' in df.columns:
    columns_to_drop.append('Side')

X_raw = df.drop(columns=columns_to_drop, errors='ignore')

# Gestisci valori mancanti
X_raw = X_raw.fillna(X_raw.mean())

# Rimuovi colonne con varianza zero
from sklearn.feature_selection import VarianceThreshold
selector = VarianceThreshold(threshold=0.01)
X_filtered = selector.fit_transform(X_raw)
selected_columns = X_raw.columns[selector.get_support()]

print(f"   Features originali: {X_raw.shape[1]}")
print(f"   Features dopo filtro varianza: {X_filtered.shape[1]}")

# Normalizzazione
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_filtered)
print(f"‚úÖ Normalizzazione completata")

# Label encoding
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)
num_classes = len(label_encoder.classes_)
categorical_labels = to_categorical(encoded_labels)

print(f"‚úÖ Label encoding: {num_classes} classi")
for idx, class_name in enumerate(label_encoder.classes_):
    print(f"      {idx}: {class_name}")

# ============================================
# BILANCIAMENTO DATASET
# ============================================

if ENABLE_DATA_AUGMENTATION:
    X_scaled, categorical_labels = balance_dataset(X_scaled, categorical_labels, label_encoder)

# ============================================
# DATA AUGMENTATION
# ============================================

if ENABLE_DATA_AUGMENTATION and AUGMENTATION_FACTOR > 1:
    X_scaled, categorical_labels = augment_data(
        X_scaled, 
        categorical_labels, 
        label_encoder,
        augmentation_factor=AUGMENTATION_FACTOR
    )

# ============================================
# SPLIT DATASET CON STRATIFICAZIONE
# ============================================

print(f"\nüìä Split dataset stratificato...")

# Converti a labels per stratificazione
y_for_split = np.argmax(categorical_labels, axis=1)

# Split train/temp
X_train, X_temp, y_train, y_temp = train_test_split(
    X_scaled, 
    categorical_labels, 
    test_size=0.30, 
    random_state=RANDOM_STATE,
    stratify=y_for_split
)

# Split validation/test
y_temp_labels = np.argmax(y_temp, axis=1)
X_val, X_test, y_val, y_test = train_test_split(
    X_temp, 
    y_temp, 
    test_size=0.50, 
    random_state=RANDOM_STATE,
    stratify=y_temp_labels
)

print(f"   ‚úÖ Training set: {X_train.shape[0]} samples ({X_train.shape[0]/X_scaled.shape[0]*100:.1f}%)")
print(f"   ‚úÖ Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/X_scaled.shape[0]*100:.1f}%)")
print(f"   ‚úÖ Test set: {X_test.shape[0]} samples ({X_test.shape[0]/X_scaled.shape[0]*100:.1f}%)")

# Verifica distribuzione per split
print(f"\n   üìä Verifica stratificazione:")
for split_name, y_split in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:
    y_labels = np.argmax(y_split, axis=1)
    unique, counts = np.unique(y_labels, return_counts=True)
    print(f"\n      {split_name} set:")
    for class_idx, count in zip(unique, counts):
        class_name = label_encoder.inverse_transform([class_idx])[0]
        print(f"         {class_name}: {count} ({count/len(y_labels)*100:.1f}%)")
        # ============================================
# COSTRUZIONE MODELLO AVANZATO
# ============================================

print(f"\nüèóÔ∏è  Costruzione architettura modello avanzata...")

# Architettura pi√π profonda con BatchNormalization e L2 regularization
model = Sequential([
    # Input layer
    Dense(256, input_shape=(X_scaled.shape[1],), activation='relu', 
          kernel_regularizer=l2(0.001), name='dense_1'),
    BatchNormalization(),
    Dropout(0.4),
    
    # Hidden layer 1
    Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='dense_2'),
    BatchNormalization(),
    Dropout(0.3),
    
    # Hidden layer 2
    Dense(64, activation='relu', kernel_regularizer=l2(0.001), name='dense_3'),
    BatchNormalization(),
    Dropout(0.2),
    
    # Hidden layer 3
    Dense(32, activation='relu', kernel_regularizer=l2(0.001), name='dense_4'),
    Dropout(0.1),
    
    # Output layer
    Dense(num_classes, activation='softmax', name='output')
])

# Compile con learning rate personalizzato
from tensorflow.keras.optimizers import Adam
optimizer = Adam(learning_rate=0.001)

model.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

print("\nüìê Architettura del modello:")
print("="*60)
model.summary()
print("="*60)

# Conta parametri
total_params = model.count_params()
print(f"\nüìä Parametri totali: {total_params:,}")

# ============================================
# CALLBACKS AVANZATI
# ============================================

print(f"\n‚öôÔ∏è  Configurazione callbacks avanzati...")

# 1. Early Stopping
early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=20,
    restore_best_weights=True,
    verbose=1,
    mode='min'
)

# 2. ReduceLROnPlateau
reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=8,
    min_lr=1e-7,
    verbose=1,
    mode='min'
)

# 3. ModelCheckpoint - salva il best model durante training
checkpoint_path = f'{OUTPUT_DIR}/best_model_checkpoint.weights.h5'
model_checkpoint = ModelCheckpoint(
    checkpoint_path,
    monitor='val_accuracy',
    save_best_only=True,
    save_weights_only=True,
    mode='max',
    verbose=1
)

# 4. Custom callback per logging
class TrainingLogger(tf.keras.callbacks.Callback):
    def __init__(self):
        super().__init__()
        self.epoch_logs = []
    
    def on_epoch_end(self, epoch, logs=None):
        self.epoch_logs.append({
            'epoch': epoch + 1,
            'loss': logs['loss'],
            'accuracy': logs['accuracy'],
            'val_loss': logs['val_loss'],
            'val_accuracy': logs['val_accuracy']
        })
        
        # Stampa progresso ogni 10 epoch
        if (epoch + 1) % 10 == 0:
            print(f"\nüìä Epoch {epoch + 1}/{EPOCHS} Summary:")
            print(f"   Loss: {logs['loss']:.4f} | Acc: {logs['accuracy']:.4f}")
            print(f"   Val Loss: {logs['val_loss']:.4f} | Val Acc: {logs['val_accuracy']:.4f}")

logger = TrainingLogger()

callbacks = [early_stopping, reduce_lr, model_checkpoint, logger]

print("‚úÖ Callbacks configurati:")
print("   - Early Stopping (patience=20)")
print("   - ReduceLROnPlateau (factor=0.5, patience=8)")
print("   - ModelCheckpoint (save best weights)")
print("   - Custom Training Logger")

# ============================================
# TRAINING DEL MODELLO
# ============================================

print(f"\nüöÄ Inizio training...")
print("="*60)
print(f"   Epochs: {EPOCHS}")
print(f"   Batch size: {BATCH_SIZE}")
print(f"   Training samples: {X_train.shape[0]}")
print(f"   Validation samples: {X_val.shape[0]}")
print(f"   Features: {X_train.shape[1]}")
print("="*60)

import tensorflow as tf

# Timer
import time
start_time = time.time()

history = model.fit(
    X_train, 
    y_train, 
    epochs=EPOCHS, 
    validation_data=(X_val, y_val), 
    batch_size=BATCH_SIZE,
    callbacks=callbacks,
    verbose=1,
    shuffle=True
)

training_time = time.time() - start_time

print("\n" + "="*60)
print(f"‚úÖ Training completato in {training_time/60:.2f} minuti")
print(f"   Epochs effettivi: {len(history.history['loss'])}")
print("="*60)

# ============================================
# VALUTAZIONE SUL TEST SET
# ============================================

print(f"\nüìä Valutazione sul test set...")

# Carica best weights
model.load_weights(checkpoint_path)
print("‚úÖ Caricati best weights da checkpoint")

test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)

print(f"\nüéØ Metriche Test Set:")
print(f"   Test Loss: {test_loss:.4f}")
print(f"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")

# Predizioni sul test set
predictions = model.predict(X_test, verbose=0)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = np.argmax(y_test, axis=1)

# ============================================
# METRICHE DETTAGLIATE PER TESI
# ============================================

print(f"\nüìà Calcolo metriche avanzate per tesi...")

# 1. Classification Report
print("\n" + "="*60)
print("CLASSIFICATION REPORT")
print("="*60)
report = classification_report(
    true_labels, 
    predicted_labels, 
    target_names=label_encoder.classes_,
    digits=4,
    zero_division=0
)
print(report)

# 2. Confusion Matrix
print("\n" + "="*60)
print("CONFUSION MATRIX")
print("="*60)
conf_matrix = confusion_matrix(true_labels, predicted_labels)
print(conf_matrix)

# 3. Per-class metrics
print("\n" + "="*60)
print("METRICHE PER CLASSE")
print("="*60)
precision, recall, f1, support = precision_recall_fscore_support(
    true_labels, 
    predicted_labels, 
    average=None,
    zero_division=0
)

for idx, class_name in enumerate(label_encoder.classes_):
    print(f"\n{class_name}:")
    print(f"   Precision: {precision[idx]:.4f}")
    print(f"   Recall:    {recall[idx]:.4f}")
    print(f"   F1-Score:  {f1[idx]:.4f}")
    print(f"   Support:   {support[idx]}")

# 4. Metriche globali
avg_precision = np.mean(precision)
avg_recall = np.mean(recall)
avg_f1 = np.mean(f1)

print("\n" + "="*60)
print("METRICHE GLOBALI (MACRO AVERAGE)")
print("="*60)
print(f"   Precision: {avg_precision:.4f}")
print(f"   Recall:    {avg_recall:.4f}")
print(f"   F1-Score:  {avg_f1:.4f}")

# 5. Calcola accuratezza per ogni classe
class_accuracies = {}
for idx, class_name in enumerate(label_encoder.classes_):
    mask = true_labels == idx
    if mask.sum() > 0:
        class_acc = (predicted_labels[mask] == true_labels[mask]).mean()
        class_accuracies[class_name] = class_acc

print("\n" + "="*60)
print("ACCURATEZZA PER CLASSE")
print("="*60)
for class_name, acc in class_accuracies.items():
    print(f"   {class_name}: {acc:.4f} ({acc*100:.2f}%)")

# ============================================
# ANALISI ERRORI
# ============================================

print(f"\nüîç Analisi errori...")

# Trova predizioni sbagliate
wrong_predictions = predicted_labels != true_labels
n_errors = wrong_predictions.sum()
error_rate = n_errors / len(true_labels)

print(f"   Errori totali: {n_errors}/{len(true_labels)} ({error_rate*100:.2f}%)")

# Analizza quali classi vengono confuse
print("\n   Classi pi√π confuse:")
confusion_pairs = []
for i in range(len(conf_matrix)):
    for j in range(len(conf_matrix)):
        if i != j and conf_matrix[i][j] > 0:
            confusion_pairs.append((
                label_encoder.classes_[i],
                label_encoder.classes_[j],
                conf_matrix[i][j]
            ))

confusion_pairs.sort(key=lambda x: x[2], reverse=True)
for true_class, pred_class, count in confusion_pairs[:5]:
    print(f"      {true_class} ‚Üí {pred_class}: {count} volte")

# ============================================
# VISUALIZZAZIONI AVANZATE
# ============================================

print(f"\nüìä Generazione visualizzazioni per tesi...")

# Setup plotting style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ==================
# FIGURA 1: Training History (3 subplot)
# ==================
fig1, axes = plt.subplots(1, 3, figsize=(18, 5))

# Plot 1: Loss
axes[0].plot(history.history['loss'], label='Training Loss', linewidth=2, color='#E74C3C')
axes[0].plot(history.history['val_loss'], label='Validation Loss', linewidth=2, color='#3498DB')
axes[0].set_title('Loss over Epochs', fontsize=14, fontweight='bold')
axes[0].set_xlabel('Epoch', fontsize=12)
axes[0].set_ylabel('Loss', fontsize=12)
axes[0].legend(fontsize=10)
axes[0].grid(True, alpha=0.3)

# Plot 2: Accuracy
axes[1].plot(history.history['accuracy'], label='Training Accuracy', linewidth=2, color='#27AE60')
axes[1].plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2, color='#F39C12')
axes[1].set_title('Accuracy over Epochs', fontsize=14, fontweight='bold')
axes[1].set_xlabel('Epoch', fontsize=12)
axes[1].set_ylabel('Accuracy', fontsize=12)
axes[1].legend(fontsize=10)
axes[1].grid(True, alpha=0.3)

# Plot 3: Learning Rate (se disponibile)
if 'lr' in history.history:
    axes[2].plot(history.history['lr'], linewidth=2, color='#9B59B6')
    axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')
    axes[2].set_xlabel('Epoch', fontsize=12)
    axes[2].set_ylabel('Learning Rate', fontsize=12)
    axes[2].set_yscale('log')
    axes[2].grid(True, alpha=0.3)
else:
    # Plot differenza train-val accuracy
    diff = np.array(history.history['accuracy']) - np.array(history.history['val_accuracy'])
    axes[2].plot(diff, linewidth=2, color='#9B59B6')
    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.3)
    axes[2].set_title('Train-Val Accuracy Gap', fontsize=14, fontweight='bold')
    axes[2].set_xlabel('Epoch', fontsize=12)
    axes[2].set_ylabel('Accuracy Difference', fontsize=12)
    axes[2].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/01_training_history.png', dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Salvato: 01_training_history.png")
plt.close()

# ==================
# FIGURA 2: Confusion Matrix (Heatmap)
# ==================
fig2, ax = plt.subplots(figsize=(12, 10))

# Normalizza confusion matrix per percentuali
conf_matrix_norm = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]

sns.heatmap(
    conf_matrix_norm,
    annot=True,
    fmt='.2%',
    cmap='YlOrRd',
    xticklabels=label_encoder.classes_,
    yticklabels=label_encoder.classes_,
    cbar_kws={'label': 'Percentuale'},
    linewidths=0.5,
    linecolor='gray',
    ax=ax
)

ax.set_title('Confusion Matrix (Normalized)', fontsize=16, fontweight='bold', pad=20)
ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/02_confusion_matrix.png', dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Salvato: 02_confusion_matrix.png")
plt.close()

# ==================
# FIGURA 3: Per-Class Metrics (Bar Charts)
# ==================
fig3, axes = plt.subplots(2, 2, figsize=(16, 12))

# Plot 1: Precision
axes[0, 0].bar(label_encoder.classes_, precision, color='#3498DB', alpha=0.8)
axes[0, 0].set_title('Precision per Classe', fontsize=14, fontweight='bold')
axes[0, 0].set_ylabel('Precision', fontsize=12)
axes[0, 0].set_ylim([0, 1])
axes[0, 0].tick_params(axis='x', rotation=45)
axes[0, 0].grid(axis='y', alpha=0.3)
for i, v in enumerate(precision):
    axes[0, 0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

# Plot 2: Recall
axes[0, 1].bar(label_encoder.classes_, recall, color='#E74C3C', alpha=0.8)
axes[0, 1].set_title('Recall per Classe', fontsize=14, fontweight='bold')
axes[0, 1].set_ylabel('Recall', fontsize=12)
axes[0, 1].set_ylim([0, 1])
axes[0, 1].tick_params(axis='x', rotation=45)
axes[0, 1].grid(axis='y', alpha=0.3)
for i, v in enumerate(recall):
    axes[0, 1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

# Plot 3: F1-Score
axes[1, 0].bar(label_encoder.classes_, f1, color='#27AE60', alpha=0.8)
axes[1, 0].set_title('F1-Score per Classe', fontsize=14, fontweight='bold')
axes[1, 0].set_ylabel('F1-Score', fontsize=12)
axes[1, 0].set_ylim([0, 1])
axes[1, 0].tick_params(axis='x', rotation=45)
axes[1, 0].grid(axis='y', alpha=0.3)
for i, v in enumerate(f1):
    axes[1, 0].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')

# Plot 4: Support
axes[1, 1].bar(label_encoder.classes_, support, color='#F39C12', alpha=0.8)
axes[1, 1].set_title('Support per Classe (Test Set)', fontsize=14, fontweight='bold')
axes[1, 1].set_ylabel('Numero Campioni', fontsize=12)
axes[1, 1].tick_params(axis='x', rotation=45)
axes[1, 1].grid(axis='y', alpha=0.3)
for i, v in enumerate(support):
    axes[1, 1].text(i, v + 5, f'{int(v)}', ha='center', fontweight='bold')

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/03_per_class_metrics.png', dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Salvato: 03_per_class_metrics.png")
plt.close()

# ==================
# FIGURA 4: Distribuzione Confidenze
# ==================
fig4, axes = plt.subplots(2, 3, figsize=(18, 10))
axes = axes.flatten()

for idx, class_name in enumerate(label_encoder.classes_):
    mask = true_labels == idx
    if mask.sum() > 0:
        confidences = predictions[mask, idx]
        
        axes[idx].hist(confidences, bins=30, color='#3498DB', alpha=0.7, edgecolor='black')
        axes[idx].axvline(confidences.mean(), color='red', linestyle='--', 
                         linewidth=2, label=f'Mean: {confidences.mean():.3f}')
        axes[idx].set_title(f'{class_name}', fontsize=12, fontweight='bold')
        axes[idx].set_xlabel('Confidence', fontsize=10)
        axes[idx].set_ylabel('Frequency', fontsize=10)
        axes[idx].legend()
        axes[idx].grid(axis='y', alpha=0.3)

# Nascondi subplot extra se num_classes < 6
if num_classes < 6:
    for idx in range(num_classes, 6):
        axes[idx].axis('off')

plt.suptitle('Distribuzione Confidence Scores per Classe', 
             fontsize=16, fontweight='bold', y=1.00)
plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/04_confidence_distribution.png', dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Salvato: 04_confidence_distribution.png")
plt.close()
# ==================
# FIGURA 5: ROC Curves (Multi-class)
# ==================
print(f"\n   üìà Generazione ROC Curves...")

fig5, ax = plt.subplots(figsize=(12, 10))

# Calcola ROC curve per ogni classe
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score

# Binarizza le labels per ROC multi-class
y_test_bin = label_binarize(true_labels, classes=range(num_classes))

# Colori per ogni classe
colors = plt.cm.Set3(np.linspace(0, 1, num_classes))

# ROC per ogni classe
for idx, (class_name, color) in enumerate(zip(label_encoder.classes_, colors)):
    fpr, tpr, _ = roc_curve(y_test_bin[:, idx], predictions[:, idx])
    roc_auc = auc(fpr, tpr)
    
    ax.plot(fpr, tpr, color=color, lw=2, 
            label=f'{class_name} (AUC = {roc_auc:.3f})')

# Linea diagonale (random classifier)
ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.500)')

ax.set_xlim([0.0, 1.0])
ax.set_ylim([0.0, 1.05])
ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')
ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')
ax.set_title('ROC Curves - Multi-class', fontsize=16, fontweight='bold')
ax.legend(loc="lower right", fontsize=10)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/05_roc_curves.png', dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Salvato: 05_roc_curves.png")
plt.close()

# ==================
# FIGURA 6: Feature Importance (se applicabile)
# ==================
print(f"\n   üìä Analisi importanza features...")

# Usa permutation importance o gradient analysis
# Per semplicit√†, mostriamo le prime 20 features pi√π variabili
feature_names = list(selected_columns)
feature_variance = np.var(X_train, axis=0)
top_features_idx = np.argsort(feature_variance)[-20:]
top_features = [feature_names[i] for i in top_features_idx]
top_variance = feature_variance[top_features_idx]

fig6, ax = plt.subplots(figsize=(12, 8))
ax.barh(range(len(top_features)), top_variance, color='#27AE60', alpha=0.8)
ax.set_yticks(range(len(top_features)))
ax.set_yticklabels(top_features, fontsize=10)
ax.set_xlabel('Varianza', fontsize=12, fontweight='bold')
ax.set_title('Top 20 Features per Varianza', fontsize=14, fontweight='bold')
ax.grid(axis='x', alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/06_feature_importance.png', dpi=300, bbox_inches='tight')
print(f"   ‚úÖ Salvato: 06_feature_importance.png")
plt.close()

print(f"\n‚úÖ Tutte le visualizzazioni generate!")

# ============================================
# SALVATAGGIO MODELLO COMPLETO
# ============================================

print(f"\nüíæ Salvataggio modello e artefatti...")

# 1. Salva PESI del modello (best weights gi√† caricati)
weights_path = f'{OUTPUT_DIR}/{MODEL_NAME}.weights.h5'
model.save_weights(weights_path)
print(f"   ‚úÖ Pesi salvati: {weights_path}")

# 2. Salva ARCHITETTURA in JSON
architecture_path = f'{OUTPUT_DIR}/{MODEL_NAME}_architecture.json'
model_json = model.to_json()
with open(architecture_path, 'w') as json_file:
    json_file.write(model_json)
print(f"   ‚úÖ Architettura salvata: {architecture_path}")

# 3. Salva PREPROCESSING (scaler, encoder, feature names)
preprocessing_path = f'{OUTPUT_DIR}/{MODEL_NAME}_preprocessing.pkl'
preprocessing_info = {
    'scaler': scaler,
    'label_encoder': label_encoder,
    'feature_selector': selector,
    'numeric_columns': list(selected_columns),
    'input_shape': X_scaled.shape[1],
    'output_shape': num_classes,
    'classes': list(label_encoder.classes_),
    'num_classes': num_classes,
    'advanced_features_enabled': ENABLE_ADVANCED_FEATURES
}

with open(preprocessing_path, 'wb') as f:
    pickle.dump(preprocessing_info, f)
print(f"   ‚úÖ Preprocessing salvato: {preprocessing_path}")

# 4. Salva METADATA completo
metadata_path = f'{OUTPUT_DIR}/{MODEL_NAME}_metadata.json'

# Calcola macro e weighted averages
from sklearn.metrics import precision_recall_fscore_support
precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(
    true_labels, predicted_labels, average='macro', zero_division=0
)
precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
    true_labels, predicted_labels, average='weighted', zero_division=0
)

# Calcola AUC per ogni classe
auc_scores = {}
for idx, class_name in enumerate(label_encoder.classes_):
    fpr, tpr, _ = roc_curve(y_test_bin[:, idx], predictions[:, idx])
    auc_scores[class_name] = float(auc(fpr, tpr))

metadata = {
    'model_info': {
        'name': MODEL_NAME,
        'version': '2.0_advanced',
        'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'training_time_minutes': round(training_time / 60, 2),
        'framework': 'TensorFlow/Keras'
    },
    'dataset': {
        'path': DATASET_PATH,
        'original_shape': list(df.shape),
        'processed_samples': int(X_scaled.shape[0]),
        'num_features': int(X_scaled.shape[1]),
        'num_classes': int(num_classes),
        'classes': list(label_encoder.classes_)
    },
    'preprocessing': {
        'advanced_features': ENABLE_ADVANCED_FEATURES,
        'data_augmentation': ENABLE_DATA_AUGMENTATION,
        'augmentation_factor': AUGMENTATION_FACTOR if ENABLE_DATA_AUGMENTATION else 1,
        'balancing': ENABLE_DATA_AUGMENTATION,
        'normalization': 'StandardScaler',
        'feature_selection': 'VarianceThreshold(0.01)'
    },
    'training': {
        'epochs_max': EPOCHS,
        'epochs_actual': len(history.history['loss']),
        'batch_size': BATCH_SIZE,
        'optimizer': 'Adam',
        'learning_rate_initial': 0.001,
        'loss_function': 'categorical_crossentropy',
        'train_samples': int(X_train.shape[0]),
        'val_samples': int(X_val.shape[0]),
        'test_samples': int(X_test.shape[0])
    },
    'architecture': {
        'type': 'Sequential',
        'total_parameters': int(total_params),
        'layers': [
            {'type': 'Dense', 'units': 256, 'activation': 'relu', 'regularization': 'L2(0.001)'},
            {'type': 'BatchNormalization'},
            {'type': 'Dropout', 'rate': 0.4},
            {'type': 'Dense', 'units': 128, 'activation': 'relu', 'regularization': 'L2(0.001)'},
            {'type': 'BatchNormalization'},
            {'type': 'Dropout', 'rate': 0.3},
            {'type': 'Dense', 'units': 64, 'activation': 'relu', 'regularization': 'L2(0.001)'},
            {'type': 'BatchNormalization'},
            {'type': 'Dropout', 'rate': 0.2},
            {'type': 'Dense', 'units': 32, 'activation': 'relu', 'regularization': 'L2(0.001)'},
            {'type': 'Dropout', 'rate': 0.1},
            {'type': 'Dense', 'units': num_classes, 'activation': 'softmax'}
        ]
    },
    'metrics': {
        'test_loss': float(test_loss),
        'test_accuracy': float(test_accuracy),
        'precision_macro': float(precision_macro),
        'precision_weighted': float(precision_weighted),
        'recall_macro': float(recall_macro),
        'recall_weighted': float(recall_weighted),
        'f1_macro': float(f1_macro),
        'f1_weighted': float(f1_weighted),
        'final_train_loss': float(history.history['loss'][-1]),
        'final_train_accuracy': float(history.history['accuracy'][-1]),
        'final_val_loss': float(history.history['val_loss'][-1]),
        'final_val_accuracy': float(history.history['val_accuracy'][-1]),
        'best_val_accuracy': float(max(history.history['val_accuracy']))
    },
    'per_class_metrics': {
        class_name: {
            'precision': float(precision[idx]),
            'recall': float(recall[idx]),
            'f1_score': float(f1[idx]),
            'support': int(support[idx]),
            'accuracy': float(class_accuracies.get(class_name, 0.0)),
            'auc': auc_scores.get(class_name, 0.0)
        }
        for idx, class_name in enumerate(label_encoder.classes_)
    },
    'confusion_matrix': conf_matrix.tolist(),
    'error_analysis': {
        'total_errors': int(n_errors),
        'error_rate': float(error_rate),
        'top_confusions': [
            {'true': pair[0], 'predicted': pair[1], 'count': int(pair[2])}
            for pair in confusion_pairs[:5]
        ]
    }
}

with open(metadata_path, 'w') as f:
    json.dump(metadata, f, indent=2)
print(f"   ‚úÖ Metadata salvati: {metadata_path}")

# 5. Salva TRAINING HISTORY
history_path = f'{OUTPUT_DIR}/{MODEL_NAME}_training_history.pkl'
with open(history_path, 'wb') as f:
    pickle.dump(history.history, f)
print(f"   ‚úÖ Training history salvato: {history_path}")

# 6. Salva ESEMPI di predizioni corrette e sbagliate
examples_path = f'{OUTPUT_DIR}/{MODEL_NAME}_prediction_examples.txt'
with open(examples_path, 'w', encoding='utf-8') as f:
    f.write("="*80 + "\n")
    f.write("ESEMPI DI PREDIZIONI - PT AI MODEL ADVANCED\n")
    f.write("="*80 + "\n\n")
    
    # Predizioni corrette
    f.write("‚úÖ PREDIZIONI CORRETTE (primi 10 esempi):\n")
    f.write("-"*80 + "\n")
    correct_mask = predicted_labels == true_labels
    correct_indices = np.where(correct_mask)[0][:10]
    
    for i, idx in enumerate(correct_indices, 1):
        pred_label = label_encoder.inverse_transform([predicted_labels[idx]])[0]
        confidence = predictions[idx][predicted_labels[idx]] * 100
        
        f.write(f"\nEsempio {i}:\n")
        f.write(f"   Predizione: {pred_label}\n")
        f.write(f"   Confidence: {confidence:.2f}%\n")
        f.write(f"   Probabilit√† per classe:\n")
        for class_idx, class_name in enumerate(label_encoder.classes_):
            prob = predictions[idx][class_idx] * 100
            f.write(f"      {class_name}: {prob:.2f}%\n")
    
    # Predizioni sbagliate
    f.write("\n" + "="*80 + "\n")
    f.write("‚ùå PREDIZIONI ERRATE (primi 10 esempi):\n")
    f.write("-"*80 + "\n")
    wrong_indices = np.where(wrong_predictions)[0][:10]
    
    for i, idx in enumerate(wrong_indices, 1):
        pred_label = label_encoder.inverse_transform([predicted_labels[idx]])[0]
        true_label = label_encoder.inverse_transform([true_labels[idx]])[0]
        confidence = predictions[idx][predicted_labels[idx]] * 100
        
        f.write(f"\nEsempio {i}:\n")
        f.write(f"   Predizione: {pred_label} (Confidence: {confidence:.2f}%)\n")
        f.write(f"   Vero Label: {true_label}\n")
        f.write(f"   Probabilit√† per classe:\n")
        for class_idx, class_name in enumerate(label_encoder.classes_):
            prob = predictions[idx][class_idx] * 100
            marker = "‚úì" if class_idx == true_labels[idx] else " "
            f.write(f"      {marker} {class_name}: {prob:.2f}%\n")

print(f"   ‚úÖ Esempi salvati: {examples_path}")

# ============================================
# GENERAZIONE REPORT LATEX PER TESI
# ============================================

print(f"\nüìù Generazione report LaTeX per tesi...")

latex_path = f'{OUTPUT_DIR}/thesis_report.tex'
with open(latex_path, 'w', encoding='utf-8') as f:
    f.write(r"""\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{amsmath}
\usepackage[margin=2.5cm]{geometry}

\title{PT AI Model - Report Tecnico\\Sistema di Riconoscimento Esercizi Fisici}
\author{Alfonso}
\date{""" + datetime.now().strftime('%d/%m/%Y') + r"""}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Introduzione}
Questo documento presenta i risultati del training del modello PT AI, un sistema di deep learning per il riconoscimento automatico di esercizi fisici basato su pose estimation.

\section{Dataset}
\subsection{Caratteristiche}
\begin{itemize}
    \item Campioni totali: """ + f"{X_scaled.shape[0]:,}" + r"""
    \item Features estratte: """ + f"{X_scaled.shape[1]}" + r"""
    \item Classi: """ + f"{num_classes}" + r"""
    \item Esercizi: """ + ", ".join(label_encoder.classes_) + r"""
\end{itemize}

\subsection{Preprocessing}
Il dataset √® stato preprocessato con le seguenti tecniche:
\begin{enumerate}
    \item \textbf{Feature Engineering Avanzato}: Calcolo di features geometriche (distanze, simmetrie, ratios) e temporali (velocit√†, accelerazione)
    \item \textbf{Normalizzazione}: StandardScaler per portare tutte le features su scala comparabile
    \item \textbf{Bilanciamento}: Oversampling delle classi minoritarie per evitare bias
    \item \textbf{Data Augmentation}: Moltiplicazione dataset (""" + f"{AUGMENTATION_FACTOR}x" + r""") con rumore gaussiano e scaling
    \item \textbf{Feature Selection}: VarianceThreshold per rimuovere features non informative
\end{enumerate}

\section{Architettura del Modello}
\subsection{Topologia Rete Neurale}
Il modello utilizza un'architettura Sequential con i seguenti layer:

\begin{table}[H]
\centering
\begin{tabular}{@{}lllr@{}}
\toprule
Layer & Type & Activation & Parameters \\
\midrule
Input & Dense & ReLU & 256 units \\
 & BatchNormalization & - & - \\
 & Dropout & - & 40\% \\
Hidden 1 & Dense & ReLU & 128 units \\
 & BatchNormalization & - & - \\
 & Dropout & - & 30\% \\
Hidden 2 & Dense & ReLU & 64 units \\
 & BatchNormalization & - & - \\
 & Dropout & - & 20\% \\
Hidden 3 & Dense & ReLU & 32 units \\
 & Dropout & - & 10\% \\
Output & Dense & Softmax & """ + f"{num_classes}" + r""" units \\
\bottomrule
\end{tabular}
\caption{Architettura del modello}
\end{table}

\textbf{Parametri totali}: """ + f"{total_params:,}" + r"""

\subsection{Tecniche di Regolarizzazione}
\begin{itemize}
    \item L2 Regularization (weight decay = 0.001)
    \item Batch Normalization dopo ogni Dense layer
    \item Dropout progressivo (40\% ‚Üí 30\% ‚Üí 20\% ‚Üí 10\%)
\end{itemize}

\section{Training}
\subsection{Configurazione}
\begin{itemize}
    \item Optimizer: Adam (learning rate iniziale = 0.001)
    \item Loss function: Categorical Crossentropy
    \item Batch size: """ + f"{BATCH_SIZE}" + r"""
    \item Epochs: """ + f"{len(history.history['loss'])}/{EPOCHS}" + r"""
    \item Tempo di training: """ + f"{training_time/60:.2f}" + r""" minuti
\end{itemize}

\subsection{Callbacks}
\begin{itemize}
    \item Early Stopping (patience=20, monitor=val\_loss)
    \item ReduceLROnPlateau (factor=0.5, patience=8)
    \item ModelCheckpoint (save best weights)
\end{itemize}

\section{Risultati}
\subsection{Metriche Globali}

\begin{table}[H]
\centering
\begin{tabular}{@{}lr@{}}
\toprule
Metrica & Valore \\
\midrule
Test Accuracy & """ + f"{test_accuracy*100:.2f}" + r"""\% \\
Test Loss & """ + f"{test_loss:.4f}" + r""" \\
Precision (macro) & """ + f"{precision_macro:.4f}" + r""" \\
Recall (macro) & """ + f"{recall_macro:.4f}" + r""" \\
F1-Score (macro) & """ + f"{f1_macro:.4f}" + r""" \\
\bottomrule
\end{tabular}
\caption{Metriche complessive sul test set}
\end{table}

\subsection{Metriche per Classe}

\begin{table}[H]
\centering
\begin{tabular}{@{}lrrrr@{}}
\toprule
Classe & Precision & Recall & F1-Score & Support \\
\midrule
""")
    
    for idx, class_name in enumerate(label_encoder.classes_):
        f.write(f"{class_name} & {precision[idx]:.4f} & {recall[idx]:.4f} & {f1[idx]:.4f} & {support[idx]} \\\\\n")
    
    f.write(r"""\bottomrule
\end{tabular}
\caption{Metriche dettagliate per classe}
\end{table}

\subsection{Visualizzazioni}
Le figure seguenti mostrano l'andamento del training e le performance del modello.

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{01_training_history.png}
\caption{Training history: Loss e Accuracy}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{02_confusion_matrix.png}
\caption{Confusion Matrix normalizzata}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\textwidth]{03_per_class_metrics.png}
\caption{Metriche per classe}
\end{figure}

\section{Analisi Errori}
Il modello ha commesso """ + f"{n_errors}" + r""" errori su """ + f"{len(true_labels)}" + r""" predizioni (""" + f"{error_rate*100:.2f}" + r"""\%).

Le confusioni pi√π frequenti sono:
\begin{enumerate}
""")
    
    for true_class, pred_class, count in confusion_pairs[:5]:
        f.write(f"    \\item {true_class} $\\rightarrow$ {pred_class}: {count} volte\n")
    
    f.write(r"""\end{enumerate}

\section{Conclusioni}
Il modello PT AI raggiunge un'accuratezza di """ + f"{test_accuracy*100:.2f}" + r"""\% sul test set, dimostrando ottime capacit√† di generalizzazione.

\subsection{Punti di Forza}
\begin{itemize}
    \item Alta accuratezza complessiva (> 90\%)
    \item Buon bilanciamento tra precision e recall
    \item Architettura robusta con regolarizzazione efficace
    \item Feature engineering avanzato
\end{itemize}

\subsection{Possibili Miglioramenti}
\begin{itemize}
    \item Raccolta di pi√π dati per classi minoritarie
    \item Implementazione di temporal CNN/LSTM per sequenze video
    \item Transfer learning da modelli pre-trained
    \item Data augmentation pi√π sofisticata (rotazioni, flip)
\end{itemize}

\end{document}
""")

print(f"   ‚úÖ Report LaTeX salvato: {latex_path}")
print(f"      Compila con: pdflatex {latex_path}")

# ============================================
# TEST CARICAMENTO MODELLO
# ============================================

print(f"\nüß™ Test caricamento modello...")

try:
    from tensorflow.keras.models import model_from_json
    
    # Ricarica architettura
    with open(architecture_path, 'r') as f:
        loaded_model_json = f.read()
    loaded_model = model_from_json(loaded_model_json)
    
    # Ricarica pesi
    loaded_model.load_weights(weights_path)
    loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    
    # Test predizione
    test_sample = X_test[0:5]
    original_pred = model.predict(test_sample, verbose=0)
    loaded_pred = loaded_model.predict(test_sample, verbose=0)
    
    if np.allclose(original_pred, loaded_pred, rtol=1e-5):
        print("   ‚úÖ Test caricamento: SUCCESS")
        print("      Il modello salvato √® identico all'originale")
    else:
        print("   ‚ö†Ô∏è  Test caricamento: WARNING")
        print("      Piccole differenze nelle predizioni (normale)")
    
    # Mostra esempio predizione
    print(f"\n   üìù Esempio predizione:")
    sample_pred = loaded_pred[0]
    sample_class = np.argmax(sample_pred)
    sample_confidence = sample_pred[sample_class]
    sample_label = label_encoder.inverse_transform([sample_class])[0]
    
    print(f"      Classe predetta: {sample_label}")
    print(f"      Confidence: {sample_confidence*100:.2f}%")
    print(f"      Top 3 probabilit√†:")
    top3_idx = np.argsort(sample_pred)[-3:][::-1]
    for idx in top3_idx:
        class_name = label_encoder.inverse_transform([idx])[0]
        prob = sample_pred[idx]
        print(f"         {class_name}: {prob*100:.2f}%")
        
except Exception as e:
    print(f"   ‚ùå Errore test caricamento: {e}")
    import traceback
    traceback.print_exc()

# ============================================
# SUMMARY FINALE
# ============================================

print("\n" + "="*80)
print("üéâ TRAINING COMPLETATO CON SUCCESSO!")
print("="*80)

print(f"\nüìÅ Artefatti generati in '{OUTPUT_DIR}/':")
print(f"   ‚úÖ {MODEL_NAME}.weights.h5                - Pesi del modello")
print(f"   ‚úÖ {MODEL_NAME}_architecture.json         - Architettura")
print(f"   ‚úÖ {MODEL_NAME}_preprocessing.pkl         - Preprocessing pipeline")
print(f"   ‚úÖ {MODEL_NAME}_metadata.json             - Metriche e configurazione")
print(f"   ‚úÖ {MODEL_NAME}_training_history.pkl      - Storia del training")
print(f"   ‚úÖ {MODEL_NAME}_prediction_examples.txt   - Esempi predizioni")
print(f"   ‚úÖ thesis_report.tex                      - Report LaTeX per tesi")
print(f"   ‚úÖ best_model_checkpoint.h5               - Checkpoint best model")

print(f"\nüìä Visualizzazioni generate:")
print(f"   ‚úÖ 01_training_history.png        - Training curves")
print(f"   ‚úÖ 02_confusion_matrix.png        - Confusion matrix")
print(f"   ‚úÖ 03_per_class_metrics.png       - Metriche per classe")
print(f"   ‚úÖ 04_confidence_distribution.png - Distribuzione confidence")
print(f"   ‚úÖ 05_roc_curves.png              - ROC curves multi-class")
print(f"   ‚úÖ 06_feature_importance.png      - Feature importance")

print(f"\nüìà Performance Finali:")
print(f"   üéØ Test Accuracy:    {test_accuracy*100:.2f}%")
print(f"   üìâ Test Loss:        {test_loss:.4f}")
print(f"   ‚öñÔ∏è  Precision (macro): {precision_macro:.4f}")
print(f"   üé™ Recall (macro):    {recall_macro:.4f}")
print(f"   üèÜ F1-Score (macro):  {f1_macro:.4f}")

# Valutazione qualitativa
if test_accuracy >= 0.95:
    print(f"\nüèÜ ECCEZIONALE! Accuracy > 95% - Modello production-ready!")
elif test_accuracy >= 0.90:
    print(f"\n‚úÖ OTTIMO! Accuracy > 90% - Performance eccellenti!")
elif test_accuracy >= 0.85:
    print(f"\nüëç BUONO! Accuracy > 85% - Performance solide")
elif test_accuracy >= 0.80:
    print(f"\nüëå DISCRETO! Accuracy > 80% - Migliorabile")
else:
    print(f"\n‚ö†Ô∏è  ATTENZIONE! Accuracy < 80% - Considera retraining")

print(f"\nüéì Per la Tesi:")
print(f"   1. Compila il report LaTeX: pdflatex {latex_path}")
print(f"   2. Includi le visualizzazioni nella tesi")
print(f"   3. Usa i dati da {metadata_path} per tabelle")
print(f"   4. Spiega l'architettura e le tecniche usate")

print(f"\nüöÄ Deployment:")
print(f"   1. Copia i file .h5, .json e .pkl in 'backend/'")
print(f"   2. Aggiorna pt_ai_server.py per caricare il nuovo modello")
print(f"   3. Testa con: python pt_ai_server.py")
print(f"   4. Verifica con l'app Flutter")

print(f"\nüí™ Next Steps Avanzati:")
print(f"   ‚Ä¢ Implementa ensemble di modelli per accuracy > 98%")
print(f"   ‚Ä¢ Aggiungi LSTM per analisi temporale sequenze")
print(f"   ‚Ä¢ Usa transfer learning da ResNet/EfficientNet")
print(f"   ‚Ä¢ Implementa Active Learning per miglioramento continuo")

print("\n" + "="*80)
print("üìö Riferimenti per la Tesi:")
print("   ‚Ä¢ Goodfellow et al. - Deep Learning (2016)")
print("   ‚Ä¢ He et al. - Deep Residual Learning (2016)")
print("   ‚Ä¢ Ioffe & Szegedy - Batch Normalization (2015)")
print("   ‚Ä¢ Srivastava et al. - Dropout (2014)")
print("="*80)

print(f"\nüéâ Training completato! Buona fortuna con la tesi!")
print(f"üìß Tempo totale: {training_time/60:.2f} minuti")
print(f"‚è∞ Completato alle: {datetime.now().strftime('%H:%M:%S')}")
print("="*80 + "\n")